# MORE Tech 4.0 Hackathon

## Track #2 DATA

### Предлагаемая структура проекта:

- input.py - модуль обработки входных данных, генератор датасета (нужен только при условии, что потребуется собирать данные например из rss-каналов)
- main_gen_features.py - генератор простых признаков из данных (нумерные, категориальные, бинарные).
- NAME_1_gen_feature.py, NAME_2_gen_feature.py ... NAME_N_gen_features.py - множество модулей по генерации сложных признаков, фичей. И если производились трансформации, то еще дополнительно выгружаются обученные модели трансформаций.

    Это надо обсудить. Такое предложение вызвано тем, что вероятно основная работа будет при обработке текста и поиска "сложных" фичей. 
Поэтому для параллельной работы по формированию фичей можно работать в отдельных модулях и независимо эксперементировать с сохранением затем итога в csv файл и потом просто склеивать в общий датафрейм все фичи. 
Плюс такого подхода, что формирование фичей может вестись каждым самостоятельно без необходимости подстраиваться под общий код. 
И по сути для обработки данных потребуется просто запустить все генераторы фичей, каждый модуль сделает свой csv файл со своими фичами. 
И общий сборщик просто объединит все файлы в один датафрейм. Еще плюс, то что процесс придумывания и тестирования новых фич вообще никак не тормозит общий процесс.   
- dataframe.py общий сборщик фичей, формирование обучающей и тестовой, нормализация, заполнение  пропусков, аугментация (типа папарное произведение числовых, объединеие числовых и категориальных и прочее). Проверка корреляции, выброс сильнозависимых между собой признаков. Важно что нормализацию данных делать в сводном модуле, это важно. 
Также, именно сводный файл будет запускать все обработчики фичей и важно чтобы это делалось и для трайн данных и для тестовых, т.е. одним функционалом все обрабатывать. 
Если получиться красиво сделать через pipeline то вообще замечательно 
- model.py модуль по построению самой модели. Вначале один модуль с одной простой моделью для расчета baseline. Далее (вероятнее всего) также будет несколько моделей + модуль агрегатор предиктов и формирования итоговых рекомендаций.

- вывод пока не учитывае, считаем что делаем простой csv с ранжированными рекомендациями.


**Вопросы:**
- что еще учесть или поправить?
 
  
### Совместная работа GitHub
Создан общий github публичный репозитарий. Почему публичный: на бесплатной версии github ограничение для приглашение в приватный репозитарий до 3 человек.
https://github.com/MORETech4/Track_2_DATA

Предлагается работать в одной ветке (чтобы не тратить время на слияние). Т.е. изначально каждый клонирует себе проект, и перед отправкой коммитов сначала делает pull к себе мержится с изменениями на сервере и только после этого делает push.
Еще раз: edit->commit->pull->merge->push

Ссылка на описание как это:
[Работа в одной ветке](https://docs.yandex.ru/docs/view?url=ya-disk-public%3A%2F%2FEs5Gmmhb72kHquqlH%2BGZHE4Atlvyzf3bmqRDSpBi988%3D&name=WorkFlow%20GithHub.pdf&nosw=1)

**Вопросы:**
- обсудить такой режим работы


### Подготовка features
Общие досутпные фичи: пол, возраст, профессия, уровень образования, структуры трат.

Производные фичи из текста новостей (то что обсуждали):
- Полезная новость — ?? непонятно что это такое. 
Это вероятно как раз то что мы и должны найти, т.е. скорее целевая функция. Т.е. полезность это реальное соответствие клиента новостям которые он читает, можно получить только из обучающей выборки именно это и должна научиться считать наша модель
- Интересная новость — Один из вариантов можно попробовать по схожести тематик клиента и схожести тематик новости. т.е. создаем 10/50/100 тематик и соотносим каждого клиента с какой-то вероятностью и то же самое делаем для каждой новости. В итоге получается 10/50/100 тематических признаков по новостям + 10/50/100 признаков по клиентам. 
На основе этого можно еще будет добавить "тематическую популярность": частота появления новости по каждой тематики у клиентов. 
- Важная новость  — ?? непонятно как считать. 
- Локализация: можно схожесть по ключевым словам, например если упоминается название регионов РФ/городов и прочее нижний уровень, если упоминаются федеральные органы или просто Россия то средний уровень, если упоминаются ключевые слова мирового значения (Европа, США, страны, мировая экономика и прочее), тогда верхний уровень.  

Еще можно: 
- Популярность новости - сходу два варианта приходит на ум: 1. это кол-во клиентов которые читают эту новость. 2. Кол-во синонимов этой новости, в случае если несколько источников новостей  
- Возрастная принадлежность новости - разбить клиентов на возрастные группы и соответствено определять процентное рапределение возрастных групп для каждой новости.   
Такой же аналог по полу делать не имеет смысл т.к. клиент и так бьется на бинарный м/ж 


**Основное** это конечно NLP обработка, но надо еще думать как прикрутить. Зависит от того как будет поставлена задача. Один из вариантов обучить NLP модель и далее подсовывать новости которые были интересны клиентам с похожими интересами.

Архитектурно пока видится такая история, что модель по NLP-обрботке текста будет использоваться и как генератор фич и как часть итоговой модели. Зависит от итоговой задачи. Это может быть как самостоятельная модель по поиску схожих новостей, может быть в составе ансамбля, может ыообще использоваться только для генерации фич по схожести новостей.      
_доп.если новостные тексты будут в виде больших статей то понадобиться еще и сегментация текста_        

**Вопросы:**
- надо придумать какие еще фичи можно выдернуть и главное как их считать 


### RoadMap (надо обсуждать и сделать примерный план) 
07.10.22
 - Ключевая задача на сегодня - сделать полную трассировку проекта от получения данных то выдачи, пусть это будет по части полей, без обработки текста ил только поиск по ключевым словам, с очень плохими весами, но в идеале сегодня должен появиться релиз v.0.0.1
 - определить пул задач (по всем направлениям, разработка, презентация, придумывание новых фичей (с объяснением как считать), ручная проверка предсказаний и т.д.) 
 - распредлить роли по задачам
 - формирвание вопросов по задачи и по данным для чекпоинтов/митапов
 - 
 
 
### Доп вопросы:
- организация работы - пока не понятно
- оперделить пул задач  
- распределеие задач по людям 
- 


 