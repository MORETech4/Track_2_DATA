# MORE Tech 4.0 Hackathon

## Track #2 DATA

Предлагаемая структура проекта:

- input.py - модуль обработки входных данных, генератор датасета (нужен только при условии, что потребуется собирать данные например из rss-каналов)
- main_features.py - генератор простых признаков из данных (нумерные, категориальные, бинарные).
- NAME_1_feature.py, NAME_2_feature.py ... NAME_N_features.py - множество модулей по генерации сложных признаков, фичей. И если производились трансформации, то еще дополнительно выгружаются обученные модели трансформаций.

    Это надо обсудить. Такое предложение вызвано тем, что вероятно основная работа будет при обработке текста и поиска "сложных" фичей. 
Поэтому для параллельной работы по формированию фичей можно работать в отдельных модулях и независимо эксперементировать с сохранением затем итога в csv файл и потом просто склеивать в общий датафрейм все фичи. 
Плюс такого подхода, что формирование фичей может вестись каждым самостоятельно без необходимости подстраиваться под общий код. 
И по сути для обработки данных потребуется просто запустить все генераторы фичей, каждый модуль сделает свой csv файл со своими фичами. 
И общий сборщик просто объединит все файлы в один датафрейм. Еще плюс, то что процесс придумывания и тестирования новых фич вообще никак не тормозит общий процесс.   
- общий сборщик фичей, формирование обучающей и тестовой, нормализация. Важно что нормализацию данных делать в сводном модуле, это важно. 
Также, именно сводный файл будет запускать все обработчики фичей и важно чтобы это делалось и для трайн данных и для тестовых, т.е. одним функционалом все обрабатывать. 
Если получиться красиво сделать через pipeline то вообще замечательно 
- модуль по построению самой модели (возможно несколько моделей + агрегатор предиктов)

- вывод пока не учитывае, считаем что делаем простой csv с ранжированными рекомендациями. 

  
            